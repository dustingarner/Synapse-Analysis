{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd               # to read in the synapse data\n",
    "import numpy as np                # for numerical data\n",
    "import matplotlib.pyplot as plt   # for plotting\n",
    "import os                         # for OS specific operations such as directory/file manipulations\n",
    "from collections import Counter\n",
    "import import_ipynb as ipy\n",
    "import csv\n",
    "from matplotlib import cm\n",
    "from annotationframeworkclient import FrameworkClient\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This is the format of creating a pd dataframe of specific synapses:\n",
    "\n",
    "df = client.materialize.query_table(\"synapses_nt_v1\", filter_in_dict = {\"pre_pt_root_id\": neur array, \"post_pt_root_id\": neur_array})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastack_name = \"flywire_fafb_production\"\n",
    "client = FrameworkClient(datastack_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.annotation.get_tables()\n",
    "\n",
    "versions = client.materialize.get_versions()\n",
    "print(versions)\n",
    "\n",
    "recent_version_info = client.materialize.get_version_metadata(versions[-1])\n",
    "print(recent_version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads xmin, xmax, ymin, ymax, zmin, zmax and converts them from pixels to nanometers\n",
    "\n",
    "region_parameters = {}\n",
    "\n",
    "region_file = pd.read_csv('') #Specify the file location\n",
    "\n",
    "for i in range(len(region_file)):\n",
    "    TempDict = {}\n",
    "    \n",
    "    for j in region_file:\n",
    "        if j != \"Region\":\n",
    "            if j == \"zmin\" or j == \"zmax\":\n",
    "                TempDict[j] = int(region_file[j][i])*40\n",
    "            else:\n",
    "                TempDict[j] = int(region_file[j][i])*4\n",
    "    \n",
    "    CurrentReg = region_file[\"Region\"][i]\n",
    "    region_parameters[CurrentReg] = TempDict\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter_df(df, Region, Autapses = False, connection_score = 0, cleft_score = 0, min_dist = [120, 120, 120]):\n",
    "    \"\"\"\n",
    "    Limits a df to various parameters.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    df (pd df): A df based on synapse data given by client.materialize.query_table()\n",
    "    Region (str): A region that is a key in the dict region_parameters\n",
    "    Autapses (bool): False if you do not want autapses in the df (default)\n",
    "    connection_score (int): The minimum connection score you want counted\n",
    "    cleft_score (int): The minimum cleft score you want counted\n",
    "    min_dist (list): The minimum distance between neurons in order to be considered different from each other.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    A pd df limited to the given region.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    Lim_df = df\n",
    "    \n",
    "    \n",
    "    RegDict = region_parameters[Region]\n",
    "    Min_Values = [RegDict[\"xmin\"], RegDict[\"ymin\"], RegDict[\"zmin\"]]\n",
    "    Max_Values = [RegDict[\"xmax\"], RegDict[\"ymax\"], RegDict[\"zmax\"]]\n",
    "    \n",
    "    Coord_Arrs = Lim_df[\"pre_pt_position\"]\n",
    "    Counter_Arr = np.zeros(len(Coord_Arrs), dtype = np.uint64)\n",
    "    for i in range(len(Coord_Arrs)):\n",
    "        for j in range(len(Coord_Arrs[i])):\n",
    "            if Coord_Arrs[i][j] > Min_Values[j] and Coord_Arrs[i][j] < Max_Values[j]:\n",
    "                Counter_Arr[i] += 1\n",
    "    \n",
    "    Lim_df[\"Temp_Arr\"] = Counter_Arr\n",
    "    Lim_df = Lim_df[Lim_df[\"Temp_Arr\"] == 3]\n",
    "    Lim_df.drop(\"Temp_Arr\", axis = 1, inplace = True)\n",
    "    \n",
    "    \n",
    "    if not Autapses:\n",
    "        Lim_df = Lim_df[Lim_df[\"pre_pt_root_id\"] != Lim_df[\"post_pt_root_id\"]]\n",
    "    \n",
    "    \n",
    "    Lim_df = Lim_df[Lim_df[\"connection_score\"] >= connection_score]\n",
    "    Lim_df = Lim_df[Lim_df[\"cleft_score\"] >= cleft_score]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    Coords = Lim_df[\"pre_pt_position\"]\n",
    "    Pre_Partner = list(Lim_df[\"pre_pt_root_id\"])\n",
    "    Post_Partner = list(Lim_df[\"post_pt_root_id\"])\n",
    "    \n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    z_list = []\n",
    "    coord_list = []\n",
    "\n",
    "    for i in Coords:\n",
    "        x_list.append(i[0])\n",
    "        y_list.append(i[1])\n",
    "        z_list.append(i[2])\n",
    "\n",
    "    id_bools = [True] * len(x_list)\n",
    "    \n",
    "    bad_coords = []\n",
    "    for i in range(len(x_list)):\n",
    "        skip_loop = False\n",
    "        for j in bad_coords:\n",
    "            if i == j:\n",
    "                skip_loop = True\n",
    "                continue\n",
    "        if skip_loop:\n",
    "            continue\n",
    "        for j in range(i+1, len(x_list)):\n",
    "            if abs(x_list[i] - x_list[j]) < min_dist[0]:\n",
    "                if abs(y_list[i] - y_list[j]) < min_dist[1]:\n",
    "                    if abs(z_list[i] - z_list[j]) < min_dist[2]:\n",
    "                        if Pre_Partner[i] == Pre_Partner[j]:\n",
    "                            if Post_Partner[i] == Post_Partner[j]:\n",
    "                                bad_coords.append(j)\n",
    "       \n",
    "    for i in bad_coords:\n",
    "        id_bools[i] = False\n",
    "    \n",
    "    Lim_df = Lim_df[id_bools]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return Lim_df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_version(ID, Region = \"connectome\"): #Enter a neuron ID, returns True or False whether that ID is in the spreadsheet\n",
    "    \"\"\"\n",
    "    To test whether a given ID is in the spreadsheet or not.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    ID (str/int): An ID to test.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    False if not in region.\n",
    "    True if in region.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    pre_df = client.materialize.query_table(\"synapses_nt_v1\", filter_in_dict = {\"post_pt_root_id\": [ID]})\n",
    "    post_df = client.materialize.query_table(\"synapses_nt_v1\", filter_in_dict = {\"pre_pt_root_id\": [ID]})\n",
    "    \n",
    "    if pre_df.empty and post_df.empty:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_neurons(Neurons, Test = True):\n",
    "    \"\"\"\n",
    "    Converts a long string of neurons into an array and prints which are not in the dataset.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    Neurons (str): An inputted list of neuron IDs separated by commas.\n",
    "    Test (bool): Tests whether the neurons are in the spreadsheet or not.\n",
    "        If True: Removes all neurons that are not in the spreadsheet and informs you of them.\n",
    "        If False: Keeps all neurons in the final array.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    The inputted neurons (that are in the dataset) in a numpy array.\n",
    "    \n",
    "    \n",
    "    --------------\n",
    "    \"\"\"\n",
    "    \n",
    "    Neurons_array = np.array([x.strip() for x in Neurons.split(\",\")], dtype = np.uint64)\n",
    "    \n",
    "    if Test:\n",
    "        not_in_spread = \"\"\n",
    "        not_in_spread_index = []\n",
    "        counter = 0\n",
    "\n",
    "        for i in Neurons_array:\n",
    "            if not in_version(i):\n",
    "                if not_in_spread == \"\":\n",
    "                    not_in_spread = str(i)\n",
    "                else:\n",
    "                    not_in_spread = not_in_spread + \",\" + str(i)\n",
    "                not_in_spread_index.append(counter)\n",
    "            counter += 1\n",
    "\n",
    "        Neurons_array = np.delete(Neurons_array, not_in_spread_index)\n",
    "\n",
    "        if not_in_spread_index:\n",
    "            print(\"\")\n",
    "            print(\"These neurons are not in the dataset: \")\n",
    "            print(not_in_spread)\n",
    "            print(\"\")\n",
    "    \n",
    "    return Neurons_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_partners(Neurons, PrePost, Region, min_syn_partners = 1):\n",
    "    \"\"\"\n",
    "    Returns a dict of all partners of a given neuron and how many synapses are between them.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    Neurons (str): A list of neuron IDs.\n",
    "    PrePost: \"pre\" or \"post\". The position in which partners you want.\n",
    "        If \"pre\": Gives all presynaptic partners to ID. ID is in \"post_pt_root_id\".\n",
    "        If \"post\": Gives all postsynaptic partners to ID. ID is in \"pre_pt_root_id\".    \n",
    "    Region (str): A specified region.\n",
    "    min_syn_partners (int): The minimum number of synaptic connections you want for a partner to be included.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    A dict.\n",
    "        Keys (int): Neuron ID.\n",
    "        Values (int): The number of synaptic connections between ID and the Key.\n",
    "        \n",
    "        \n",
    "    Prerequisites\n",
    "    -------------\n",
    "    array_neurons (function)\n",
    "    iterate_syn (function)\n",
    "    LimRegion (function)\n",
    "    region_parameters (dict)\n",
    "    \n",
    "    \n",
    "    -------------\n",
    "    \"\"\"\n",
    "    \n",
    "    neur_array = array_neurons(Neurons)\n",
    "        \n",
    "    if PrePost == \"pre\":\n",
    "        df = client.materialize.query_table(\"synapses_nt_v1\", filter_in_dict = {\"post_pt_root_id\": neur_array})\n",
    "        df = Filter_df(df, Region)\n",
    "        listed = list(df[\"pre_pt_root_id\"])\n",
    "    elif PrePost == \"post\":\n",
    "        df = client.materialize.query_table(\"synapses_nt_v1\", filter_in_dict = {\"pre_pt_root_id\": neur_array})\n",
    "        df = Filter_df(df, Region)\n",
    "        listed = list(df[\"post_pt_root_id\"])\n",
    "    else:\n",
    "        return 'Please enter \"pre\" or \"post\" for PrePost'\n",
    "    \n",
    "    listed_unique = list(set(listed))\n",
    "    remove_neurons = []\n",
    "\n",
    "    for i in listed_unique:\n",
    "        if listed.count(i) < min_syn_partners:\n",
    "            remove_neurons.append(i)\n",
    "    \n",
    "    for i in remove_neurons:\n",
    "        while i in listed:\n",
    "            listed.remove(i)\n",
    "    \n",
    "    ordered = Counter(listed)\n",
    "    ordered = dict(sorted(ordered.items(), key = lambda x: x[1], reverse = True))\n",
    "    \n",
    "    return ordered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_connectome(PrePartners, PostPartners, Region):\n",
    "    \"\"\"\n",
    "    Makes a numpy array of number of synapses between PrePartners and PostPartners.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    PrePartners (str): All the presynaptic neurons, will create the rows, will go through array_neurons.\n",
    "    PostPartners (str): All the postsynaptic neurons, will create the columns, will go through array_neurons.\n",
    "    Region: The region the synapses are limited to.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    An array with the synapses between the PrePartners and PostPartners.\n",
    "    \n",
    "    \n",
    "    Prerequisites\n",
    "    -------------\n",
    "    array_neurons (function)\n",
    "    dict_partners (function)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    Pre_Array = array_neurons(PrePartners)\n",
    "    Post_Array = array_neurons(PostPartners)\n",
    "    \n",
    "    m = Pre_Array.size\n",
    "    n = Post_Array.size\n",
    "    \n",
    "    syn_map = np.zeros((m,n), dtype = np.uint64)\n",
    "    print(\"Number of presynaptic neurons: \", m)\n",
    "    print(\"Number of postsynaptic neurons: \", n)\n",
    "    print(\"========================================\")\n",
    "\n",
    "    for i in range(0, m):\n",
    "        Current_Pre_Partners = dict_partners(str(Pre_Array[i]), \"post\", Region)\n",
    "        \n",
    "        for j in range(0,n):\n",
    "            if Post_Array[j] in Current_Pre_Partners:\n",
    "                syn_map[i,j] = Current_Pre_Partners[Post_Array[j]]\n",
    "    \n",
    "    return syn_map\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_connectivity(pre_keys, post_keys, Region, Graph_Name = \"Synaptic Connections\", binarizing_threshold=5):\n",
    "    \"\"\"\n",
    "    Plots the number of synapses between pre and post neurons.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    pre_keys (np array): An array in which each value is a string which is a key in syn_dict_dnu. Will be the types of neurons analyzed as presynaptic.\n",
    "    post_keys (np array): An array in which each value is a string which is a key in syn_dict_dnu. Will be the types of neurons analyzed as postsynaptic.\n",
    "    Region (str): The region to which the plot will be limited.\n",
    "    Graph_Name (str): The title of the graph.\n",
    "    binarizing_threshold (int): Not 100% sure.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    A figure plotting the number of synapses between pre and post neurons.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Prerequisites\n",
    "    --------------\n",
    "    array_neurons (function)\n",
    "    extract_connectome (function)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    pre_ns = np.zeros(pre_keys.size, dtype = int)\n",
    "    pre_label_position = np.zeros(2*pre_keys.size, dtype = float)\n",
    "    pre_neurons = \"\"\n",
    "    pre_label_list = np.array([], dtype = str)\n",
    "    \n",
    "    for i in range(pre_keys.size):\n",
    "        current_type = pre_keys[i]\n",
    "        current_neur_array = array_neurons(syn_dict_dnu[current_type])\n",
    "        pre_ns[i] = current_neur_array.size\n",
    "        pre_label_position[2*i] = sum(pre_ns) - pre_ns[i] - 0.5\n",
    "        pre_label_position[2*i + 1] = sum(pre_ns) - pre_ns[i]/2 - 0.5\n",
    "        if i == 0:\n",
    "            pre_neurons = pre_neurons + syn_dict_dnu[current_type]\n",
    "        else:\n",
    "            pre_neurons = pre_neurons + \",\" + syn_dict_dnu[current_type]\n",
    "        pre_label_list = np.concatenate([pre_label_list,['–––––––––––', current_type]])\n",
    "    pre_label_position = np.concatenate([pre_label_position, [sum(pre_ns) - 0.5]])\n",
    "    pre_label_list = np.concatenate([pre_label_list, ['–––––––––––']])\n",
    "    \n",
    "    post_ns = np.zeros(post_keys.size, dtype = int)\n",
    "    post_label_position = np.zeros(2*post_keys.size, dtype = float)\n",
    "    post_neurons = \"\"\n",
    "    post_label_list = np.array([], dtype = str)\n",
    "    \n",
    "    for i in range(post_keys.size):\n",
    "        current_type = post_keys[i]\n",
    "        current_neur_array = array_neurons(syn_dict_dnu[current_type])\n",
    "        post_ns[i] = current_neur_array.size\n",
    "        post_label_position[2*i] = sum(post_ns) - post_ns[i] - 0.5\n",
    "        post_label_position[2*i + 1] = sum(post_ns) - post_ns[i]/2 - 0.5\n",
    "        if i == 0:\n",
    "            post_neurons = post_neurons + syn_dict_dnu[current_type]\n",
    "        else:\n",
    "            post_neurons = post_neurons + \",\" + syn_dict_dnu[current_type]        \n",
    "        post_label_list = np.concatenate([post_label_list,['–––––––––––', current_type]])\n",
    "    post_label_position = np.concatenate([post_label_position, [sum(post_ns) - 0.5]])\n",
    "    post_label_list = np.concatenate([post_label_list, ['–––––––––––']])\n",
    "    \n",
    "    synapses_array = extract_connectome(pre_neurons, post_neurons, Region)\n",
    "    \n",
    "    for p in range(2):\n",
    "        separator = ', ' \n",
    "        tstr = separator.join(pre_keys) #joins the type names with comma and space\n",
    "        \n",
    "        # If the title string is too long, then the file name may generate an error\n",
    "        if len(tstr)>100:\n",
    "            tstr = tstr[0:100]\n",
    "        if p==0: # plot the original\n",
    "            title_str = tstr\n",
    "        else:    # plot the binarized version\n",
    "            synapses_array[synapses_array<binarizing_threshold] = 0\n",
    "            synapses_array[synapses_array>=binarizing_threshold] = 1\n",
    "            title_str = tstr + ' (binarized)'\n",
    "\n",
    "        # Draw a figure\n",
    "        figA = plt.figure(figsize = (15,15))\n",
    "        ax1 = figA.add_subplot(1,1,1)\n",
    "        img = ax1.imshow(synapses_array, cmap = plt.get_cmap(\"Purples\"), interpolation='none')\n",
    "        figA.colorbar(img, ax=ax1)\n",
    "\n",
    "        ax1.set_title(Graph_Name)\n",
    "\n",
    "        ax1.set_xlabel('Post-Synaptic Neurons')\n",
    "        ax1.set_xticks(post_label_position)\n",
    "        ax1.set_xticklabels(post_label_list,rotation=90)\n",
    "        #ax1.set_xticklabels(label_list)\n",
    "\n",
    "        ax1.set_ylabel('Pre-Synaptic Neurons')\n",
    "        ax1.set_yticks(pre_label_position)\n",
    "        ax1.set_yticklabels(pre_label_list)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        figA.savefig(\n",
    "                os.path.join('figures', title_str + '.png'), format='png',  # PNG plot keeps the resolution but the font is distorted. PDF is opposite.\n",
    "                bbox_inches='tight',\n",
    "                #transparent=True,\n",
    "                pad_inches=0.1,\n",
    "                dpi=150 # For publication, use higher dpi\n",
    "            ) \n",
    "\n",
    "\n",
    "    \n",
    "    return figA\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takes a while (only run if making connectivity charts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For importing neuron types from txt file\"\"\"\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "syn_dict_dnu = {}\n",
    "\n",
    "with open('' , 'r', encoding = \"utf8\") as f: #Specify the file location\n",
    "    \n",
    "    lines = f.readlines()\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        \n",
    "        if lines[i] == \"Neuron Type:\\n\":\n",
    "            types = [x.strip() for x in lines[i+1].split(\",\")]\n",
    "            \n",
    "            neurons = lines[i+2].strip()\n",
    "            print(\"\")\n",
    "            print(types)\n",
    "            if not neurons == \"\":\n",
    "                array_neurons(neurons)\n",
    "            \n",
    "            for j in types:\n",
    "                if not j in syn_dict_dnu:\n",
    "                    syn_dict_dnu[j] = neurons\n",
    "                else:\n",
    "                    syn_dict_dnu[j] = syn_dict_dnu[j] + \",\" + neurons\n",
    "\n",
    "\n",
    "print(syn_dict_dnu)\n",
    "\n",
    "print(\"My program took\", time.time() - start_time, \"to run\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below are all of the different things you can do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Enter a long list of neurons in and see which are in the spreadsheet and which aren't.\n",
    "\"\"\"\n",
    "\n",
    "All_Neurons = input(\"Please enter neuron(s): \")\n",
    "All_Neurons = array_neurons(All_Neurons, Test = False)\n",
    "\n",
    "in_spread = \"\"\n",
    "not_in_spread = \"\"\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "\n",
    "for i in All_Neurons:\n",
    "    if in_version(i):\n",
    "        if in_spread == \"\":\n",
    "            in_spread = str(i)\n",
    "        else:\n",
    "            in_spread = in_spread + \",\" + str(i)\n",
    "        count1 += 1\n",
    "    else:\n",
    "        if not_in_spread == \"\":\n",
    "            not_in_spread = str(i)\n",
    "        else:\n",
    "            not_in_spread = not_in_spread + \",\" + str(i)\n",
    "        count2 += 1\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"These neurons are in the spreadsheet: \")\n",
    "print(in_spread)\n",
    "print(\"There are \" + str(count1) + \" neurons.\")\n",
    "print(\"\")\n",
    "print(\"These neurons are not in the spreadsheet: \")\n",
    "print(not_in_spread)\n",
    "print(\"There are \" + str(count1 + count2) + \" total neurons.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Enter neuron(s) and find their partners.\n",
    "\"\"\"\n",
    "\n",
    "neurs = input(\"Please enter neurons: \")\n",
    "Region = input(\"What region? \")\n",
    "PrePost = input(\"Would you like pre or post partners? \")\n",
    "\n",
    "partners = dict_partners(neurs, PrePost, Region, min_syn_partners = 5)\n",
    "print(\"\")\n",
    "print(partners)\n",
    "print(\"\")    \n",
    "print(list(partners.keys()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make a synaptic map and export it to excel.\n",
    "\"\"\"\n",
    "\n",
    "Pre = input(\"Pre partners: \")\n",
    "Post = input(\"Post partners: \")\n",
    "Region = input(\"Please enter the region: \")\n",
    "\n",
    "excel_maybe = input(\"Export to excel? (yes or no): \")\n",
    "if excel_maybe == \"yes\":\n",
    "    name = input(\"Name of File: \")\n",
    "\n",
    "Map = extract_connectome(Pre, Post, Region)\n",
    "print(Map)\n",
    "\n",
    "if excel_maybe == \"yes\":\n",
    "    excel = pd.DataFrame(data = Map)\n",
    "    out_path = '' + name + '.xlsx' #Specify the desired file path\n",
    "    excel.to_excel(out_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make a synaptic plot.\n",
    "\"\"\"\n",
    "\n",
    "Pre_Types = input(\"Pre partner types: \")\n",
    "Post_Types = input(\"Post partner types: \")\n",
    "Pre = np.array([x.strip() for x in Pre_Types.split(\",\")], dtype = str)\n",
    "Post = np.array([x.strip() for x in Post_Types.split(\",\")], dtype = str)\n",
    "\n",
    "Region = input(\"Please enter the region: \")\n",
    "\n",
    "Map = plot_connectivity(Pre, Post, Region)\n",
    "print(Map)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ranks the likelihoods of neurotransmitters used by a neuron.\n",
    "\"\"\"\n",
    "ID = input(\"Please enter neuron: \")\n",
    "syn_df = client.materialize.query_table(\"synapses_nt_v1\", filter_in_dict = {\"pre_pt_root_id\": [ID]})\n",
    "\n",
    "Region = input(\"Please enter region: \")\n",
    "syn_df = Filter_df(syn_df, Region)\n",
    "\n",
    "nt_dict = {}\n",
    "\n",
    "NTs = [\"gaba\", \"ach\", \"glut\", \"oct\", \"ser\", \"da\"]\n",
    "\n",
    "for i in NTs:\n",
    "    nt_dict[i] = sum(list(syn_df[i]))/len(syn_df[i])\n",
    "\n",
    "ordered = sorted(nt_dict.items(), key = lambda x: x[1], reverse = True)\n",
    "print(ordered)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Makes a csv file of all of the synapses between presynaptic and postsynaptic partners.\n",
    "\"\"\"\n",
    "Pre = input(\"Please enter presynaptic partner(s): \")\n",
    "Post = input(\"Please enter postsynaptic partner(s): \")\n",
    "Region = input(\"Please enter region: \")\n",
    "name = input(\"Please create a file name: \")\n",
    "\n",
    "print(\"Pre: \")\n",
    "Pre = array_neurons(Pre)\n",
    "print(\"\")\n",
    "print(\"Post:\")\n",
    "Post = array_neurons(Post)\n",
    "print(\"\")\n",
    "\n",
    "df = client.materialize.query_table(\"synapses_nt_v1\", filter_in_dict = {\"pre_pt_root_id\": Pre, \"post_pt_root_id\": Post})\n",
    "df = Filter_df(df, Region)\n",
    "\n",
    "Temp_Coords = list(df[\"pre_pt_position\"])\n",
    "Coords = []\n",
    "for i in Temp_Coords:\n",
    "    Coords.append(\"(\" + str(int(i[0]/4)) + \", \" + str(int(i[1]/4)) + \", \" + str(int(i[2]/40)) + \")\")\n",
    "    \n",
    "count = list(range(1,len(Coords)+1))\n",
    "\n",
    "\n",
    "out_path = '' + name + '.csv' #Specify the desired file path\n",
    "head = [\"Coordinate 1\", \"Coordinate 2\", \"Ellipsoid Dimensions\", \"Tags\", \"Description\", \"Segments IDs\", \"Parent ID\", \"Type\", \"ID\"]\n",
    "\n",
    "\n",
    "with open(out_path, \"w\", newline = \"\") as file:\n",
    "    thewriter = csv.writer(file)\n",
    "\n",
    "    thewriter.writerow(head)\n",
    "\n",
    "    count = 1\n",
    "    for j in range(len(Coords)):\n",
    "        Rows = [Coords[j], \"\", \"\", \"\", count, \"\", \"\", \"Point\", \"\"]\n",
    "        thewriter.writerow(Rows)\n",
    "\n",
    "        count+=1\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reorders a set of neurons.\n",
    "\"\"\"\n",
    "\n",
    "order = []\n",
    "\n",
    "old_neurs = []\n",
    "\n",
    "new_neurs = [old_neurs[i] for i in order]\n",
    "\n",
    "print(new_neurs)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
